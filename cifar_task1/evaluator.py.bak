# -*- coding: utf-8 -*-
from __future__ import annotations
import importlib.util, json, os, sys, time, traceback, hashlib, random
from typing import Any, Dict, Tuple

import torch
from torch import nn
from torch.utils.data import DataLoader, Subset
import torchvision
import torchvision.transforms as T

# 兼容 OpenEvolve 的 EvaluationResult
try:
    from openevolve.evaluation_result import EvaluationResult  # type: ignore
    def _wrap(metrics: Dict[str, Any], artifacts: Dict[str, Any]):
        return EvaluationResult(metrics=metrics, artifacts=artifacts)
except Exception:
    def _wrap(metrics: Dict[str, Any], artifacts: Dict[str, Any]):
        return {"metrics": metrics, "artifacts": artifacts}

# ---------- 固定的评测设置（仿 examples/function_minimization：评估全在 evaluator） ----------
ART_DIR = os.environ.get("OE_ART_DIR", "openevolve_output/manual_artifacts")
os.makedirs(ART_DIR, exist_ok=True)

EVAL_CONFIG = {
    "data_root": "/data/lz/openevolve/dataset/cifar-10-batches-py",  # 你的路径
    "device": "cpu",           # 统一 CPU 计时，稳定可比；如需 GPU 改成 "cuda"
    "epochs": 1,               # 轻量训练，加快演化
    "batch_size": 16,
    "lr": 1e-2,
    "weight_decay": 0.0,
    "num_workers": 0,
    "train_count": 100,
    "test_count": 100,
}

CONTRACT_TEXT = (
    "REQUIRED CONTRACT for candidate program:\n"
    "1) Provide function build_candidate() -> (model: torch.nn.Module, structure_signature: dict|None).\n"
    "2) Do NOT: read/download data, train, eval, I/O or logging; evaluator handles all.\n"
    "3) The returned model must accept input shape [N,3,32,32] and output logits [N,10].\n"
)

# ---------- 工具 ----------
def _seed_all(seed: int = 42):
    random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

def _safe_import(module_path: str):
    name = os.path.splitext(os.path.basename(module_path))[0]
    spec = importlib.util.spec_from_file_location(name, module_path)
    if spec is None or spec.loader is None:
        raise ImportError(f"Cannot load module from {module_path}")
    module = importlib.util.module_from_spec(spec)
    sys.modules[name] = module
    spec.loader.exec_module(module)  # type: ignore
    return module

def _resolve_torchvision_root(path: str) -> str:
    p = path.rstrip("/")
    return os.path.dirname(p) if p.endswith("cifar-10-batches-py") else p

def _subset_cifar10(train: bool, seed: int, count: int, data_root: str):
    tfm = T.Compose([
        T.ToTensor(),
        T.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261)),
    ])
    root = _resolve_torchvision_root(data_root)
    if not os.path.exists(os.path.join(root, "cifar-10-batches-py")):
        raise FileNotFoundError(f"CIFAR-10 not found under '{root}/cifar-10-batches-py'")
    ds = torchvision.datasets.CIFAR10(root=root, train=train, download=False, transform=tfm)
    g = torch.Generator().manual_seed(seed)
    idx = torch.randperm(len(ds), generator=g)[:count]
    return Subset(ds, idx)

def _count_params(model: nn.Module) -> int:
    return sum(p.numel() for p in model.parameters())

def _latency_ms_per_sample(model: nn.Module, device: torch.device, runs: int = 20) -> float:
    model.eval()
    x = torch.randn((1, 3, 32, 32), device=device)
    with torch.no_grad():
        for _ in range(5):
            _ = model(x)
        if device.type == "cuda":
            torch.cuda.synchronize()
        start = time.perf_counter()
        for _ in range(runs):
            _ = model(x)
        if device.type == "cuda":
            torch.cuda.synchronize()
        elapsed = time.perf_counter() - start
    return float((elapsed / runs) * 1000.0)

def _combined_score(acc: float, latency_ms: float, params: int) -> float:
    # function_minimization 风格的单指标：这里综合精度/时延/参数
    return (acc * 100.0) - 0.05 * latency_ms - 0.0001 * params

def _mk_tag(program_path: str) -> str:
    import hashlib, time
    h = hashlib.sha1(program_path.encode("utf-8")).hexdigest()[:8]
    return f"{int(time.time()*1000)}_{h}"

def _dump(tag: str, kind: str, payload: Dict[str, Any]):
    path = os.path.join(ART_DIR, f"{tag}.{kind}.json")
    try:
        with open(path, "w", encoding="utf-8") as f:
            json.dump(payload, f, ensure_ascii=False, indent=2)
    except Exception:
        pass
    return path

# ---------- 评测主流程（仿 examples/function_minimization） ----------
def evaluate(program_path: str):
    tag = _mk_tag(program_path)
    _seed_all(42)

    try:
        mod = _safe_import(program_path)
        if not hasattr(mod, "build_candidate"):
            raise AttributeError("Missing build_candidate().\n" + CONTRACT_TEXT)

        # 只允许 build_candidate 构造结构；其余训练/数据由 evaluator 统一执行
        ret = mod.build_candidate()
        if isinstance(ret, tuple):
            model, structure = ret[0], (ret[1] if len(ret) > 1 else {})
        else:
            model, structure = ret, {}

        if not isinstance(model, nn.Module):
            raise TypeError("build_candidate must return a torch.nn.Module (optionally with a structure dict).")

        # 固定数据
        cfg = EVAL_CONFIG
        device = torch.device(cfg["device"])
        train_ds = _subset_cifar10(True,  seed=42, count=cfg["train_count"], data_root=cfg["data_root"])
        test_ds  = _subset_cifar10(False, seed=43, count=cfg["test_count"],  data_root=cfg["data_root"])
        train_loader = DataLoader(train_ds, batch_size=cfg["batch_size"], shuffle=True,
                                  num_workers=cfg["num_workers"], pin_memory=(device.type=="cuda"))
        test_loader  = DataLoader(test_ds, batch_size=128, shuffle=False,
                                  num_workers=cfg["num_workers"], pin_memory=(device.type=="cuda"))

        # 训练
        model = model.to(device)
        params = _count_params(model)
        optim = torch.optim.SGD(model.parameters(), lr=cfg["lr"], weight_decay=cfg["weight_decay"], momentum=0.9)
        criterion = nn.CrossEntropyLoss()

        model.train()
        for _ in range(cfg["epochs"]):
            for images, labels in train_loader:
                images, labels = images.to(device), labels.to(device)
                logits = model(images)
                loss = criterion(logits, labels)
                optim.zero_grad(set_to_none=True)
                loss.backward()
                optim.step()

        # 测试
        model.eval()
        correct, total = 0, 0
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                pred = model(images).argmax(dim=1)
                correct += int((pred == labels).sum().item())
                total += int(labels.numel())
        test_acc = correct / max(1, total)

        # 延迟
        latency_ms = _latency_ms_per_sample(model, device, runs=20)

        # 指标 + artifacts（与 function_minimization 一样，把关键信息吐出来）
        metrics = {
            "test_acc": float(test_acc),
            "latency_ms_per_sample": float(latency_ms),
            "params": int(params),
            "feature_speed": 1.0 / (1.0 + latency_ms),
            "feature_complexity": min(1.0, params / 1_000_000.0),
        }
        metrics["combined_score"] = _combined_score(test_acc, latency_ms, params)

        artifacts = {
            "structure_signature": json.dumps(structure or {}, ensure_ascii=False, indent=2),
            "contract": CONTRACT_TEXT,
            "eval_config_used": json.dumps(EVAL_CONFIG),
            "raw_program_path": program_path,
            "directional_feedback": (
                f"acc={test_acc:.3f}, latency={latency_ms:.2f}ms, params={params}. "
                "Try: block tiling for inner accumulation; vectorize with addmm/einsum; "
                "add a tiny 3×3 conv stem; apply low-rank or sparsity to cut MACs."
            ),
        }

        _dump(tag, "metrics", metrics)
        _dump(tag, "artifacts", artifacts)
        return _wrap(metrics, artifacts)

    except Exception as e:
        tb = traceback.format_exc()
        artifacts = {
            "exception": str(e),
            "traceback": tb,
            "contract": CONTRACT_TEXT,
            "eval_config_used": json.dumps(EVAL_CONFIG),
            "raw_program_path": program_path,
            "repair_suggestions": (
                "Only modify build_candidate(); return a torch.nn.Module (and optional structure dict); "
                "do not touch data/training/IO; ensure input [N,3,32,32] → logits [N,10]."
            ),
        }
        metrics = {"combined_score": -1e9, "error": 1.0}
        # 控制台打印，便于直接在日志里可见
        try:
            print(json.dumps(artifacts, ensure_ascii=False, indent=2))
        except Exception:
            pass
        _dump(tag, "metrics", metrics)
        _dump(tag, "artifacts", artifacts)
        return _wrap(metrics, artifacts)


if __name__ == "__main__":
    p = sys.argv[1] if len(sys.argv) > 1 else "./initial_program.py"
    out = evaluate(p)
    print(out)
