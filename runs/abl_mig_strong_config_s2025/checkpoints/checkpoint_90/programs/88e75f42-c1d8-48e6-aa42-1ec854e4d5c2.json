{"id": "88e75f42-c1d8-48e6-aa42-1ec854e4d5c2", "code": "# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid random search algorithm for function minimization within specified bounds.\n    \n    Combines global exploration with local refinement around promising solutions to \n    balance exploration and exploitation of the search space.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random coordinates\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n    \n    # Probability of performing local search around best solution\n    local_search_prob = 0.2\n\n    for _ in range(iterations):\n        # Hybrid search strategy: balance exploration and exploitation\n        if np.random.random() < local_search_prob:\n            # Local search: refine around current best solution with fixed perturbation\n            x = np.clip(best_x + np.random.normal(0, 0.5), bounds[0], bounds[1])\n            y = np.clip(best_y + np.random.normal(0, 0.5), bounds[0], bounds[1])\n        else:\n            # Global search: explore new random point\n            x, y = np.random.uniform(*bounds, size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n", "language": "python", "parent_id": "f26f7c83-fde4-4310-982d-dc1c4a311fe2", "generation": 4, "timestamp": 1755441417.8868384, "iteration_found": 88, "metrics": {"runs_successfully": 1.0, "value_score": 0.9967961734969121, "distance_score": 0.9532631028909082, "overall_score": 0.9948902111934126, "standard_deviation_score": 0.9596515461566286, "speed_score": 1.0, "reliability_score": 1.0, "combined_score": 0.9744510559670628, "success_rate": 1.0}, "complexity": 0.0, "diversity": 0.0, "metadata": {"changes": "Change 1: Replace 24 lines with 34 lines", "parent_metrics": {"runs_successfully": 1.0, "value_score": 0.9706450318711667, "distance_score": 0.8588456976355067, "overall_score": 0.9836785335995158, "standard_deviation_score": 0.8903545633512158, "speed_score": 1.0, "reliability_score": 1.0, "combined_score": 0.9183926679975789, "success_rate": 1.0}, "island": 2}, "artifacts_json": null, "artifact_dir": null, "prompts": {"diff_user": {"system": "You are an expert coder helping to improve programs through evolution.", "user": "# Current Program Information\n- Current performance metrics: - runs_successfully: 1.0000\n- value_score: 0.9706\n- distance_score: 0.8588\n- overall_score: 0.9837\n- standard_deviation_score: 0.8904\n- speed_score: 1.0000\n- reliability_score: 1.0000\n- combined_score: 0.9184\n- success_rate: 1.0000\n- Areas identified for improvement: - Consider simplifying the code to improve readability and maintainability\n- Metrics showing regression: value_score, distance_score, overall_score, standard_deviation_score, combined_score. Consider reverting or revising recent changes in these areas.\n\n\n\n# Program Evolution History\n## Previous Attempts\n\n### Attempt 3\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, value_score: 0.9960, distance_score: 0.9498, overall_score: 0.9946, standard_deviation_score: 0.9599, speed_score: 1.0000, reliability_score: 1.0000, combined_score: 0.9730, success_rate: 1.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 2\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, value_score: 0.9970, distance_score: 0.9544, overall_score: 0.9952, standard_deviation_score: 0.9649, speed_score: 1.0000, reliability_score: 1.0000, combined_score: 0.9760, success_rate: 1.0000\n- Outcome: Improvement in all metrics\n\n\n### Attempt 1\n- Changes: Unknown changes\n- Performance: runs_successfully: 1.0000, value_score: 0.9974, distance_score: 0.9562, overall_score: 0.9954, standard_deviation_score: 0.9672, speed_score: 1.0000, reliability_score: 1.0000, combined_score: 0.9772, success_rate: 1.0000\n- Outcome: Improvement in all metrics\n\n## Top Performing Programs\n\n### Program 1 (Score: 0.9881)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid random search algorithm for function minimization within specified bounds.\n    \n    Combines global exploration with local refinement around promising solutions to \n    balance exploration and exploitation of the search space.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random coordinates\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n    \n    # Probability of performing local search around best solution\n    local_search_prob = 0.2\n\n    for _ in range(iterations):\n        # Hybrid search strategy: balance exploration and exploitation\n        if np.random.random() < local_search_prob:\n            # Local search: refine around current best solution with fixed perturbation\n            x = np.clip(best_x + np.random.normal(0, 0.5), bounds[0], bounds[1])\n            y = np.clip(best_y + np.random.normal(0, 0.5), bounds[0], bounds[1])\n        else:\n            # Global search: explore new random point\n            x, y = np.random.uniform(*bounds, size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9974), Performs well on distance_score (0.9562), Performs well on overall_score (0.9954), Performs well on standard_deviation_score (0.9672), Performs well on speed_score (1.0000), Performs well on reliability_score (1.0000), Performs well on combined_score (0.9772), Performs well on success_rate (1.0000)\n\n\n### Program 2 (Score: 0.9875)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Adaptive random search algorithm for function minimization within specified bounds.\n    \n    Combines global exploration with local refinement around promising solutions.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random point using uniform distribution\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Adaptive search: explore globally and refine locally\n        if np.random.random() < 0.2:  # 20% chance to refine around best found\n            # Add small perturbation to best solution\n            x = best_x + np.random.normal(0, 0.5)\n            y = best_y + np.random.normal(0, 0.5)\n            # Keep within bounds\n            x = np.clip(x, bounds[0], bounds[1])\n            y = np.clip(y, bounds[0], bounds[1])\n        else:  # 80% chance for global exploration\n            x, y = np.random.uniform(*bounds, size=2)\n            \n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9970), Performs well on distance_score (0.9544), Performs well on overall_score (0.9952), Performs well on standard_deviation_score (0.9649), Performs well on speed_score (1.0000), Performs well on reliability_score (1.0000), Performs well on combined_score (0.9760), Performs well on success_rate (1.0000)\n\n\n### Program 3 (Score: 0.9859)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Random search algorithm for function minimization within specified bounds.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random starting point\n    best_x, best_y = np.random.uniform(bounds[0], bounds[1], 2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Adaptive search: explore globally and refine locally\n        if np.random.random() < 0.2:  # 20% chance to refine around best found\n            # Add small perturbation to best solution\n            x = best_x + np.random.normal(0, 0.5)\n            y = best_y + np.random.normal(0, 0.5)\n            # Keep within bounds\n            x = np.clip(x, bounds[0], bounds[1])\n            y = np.clip(y, bounds[0], bounds[1])\n        else:  # 80% chance for global exploration\n            x, y = np.random.uniform(bounds[0], bounds[1], 2)\n            \n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Performs well on runs_successfully (1.0000), Performs well on value_score (0.9960), Performs well on distance_score (0.9498), Performs well on overall_score (0.9946), Performs well on standard_deviation_score (0.9599), Performs well on speed_score (1.0000), Performs well on reliability_score (1.0000), Performs well on combined_score (0.9730), Performs well on success_rate (1.0000)\n\n\n\n\n## Diverse Programs\n\n### Program D1 (Score: 0.9766)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid search algorithm balancing exploration and exploitation.\n    \n    Combines global random search with local refinement around promising solutions\n    to efficiently find function minima within specified bounds.\n    \n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Search space boundaries as (min, max) (default: (-5, 5))\n        \n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random point\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n    \n    # Probability of local vs global search (10% local balances exploration/exploitation)\n    local_search_prob = 0.1\n    \n    for _ in range(iterations):\n        # Adaptive search strategy\n        if np.random.random() < local_search_prob:\n            # Local search: explore around best solution with normal distribution\n            search_width = (bounds[1] - bounds[0]) / 10  # 10% of search space for focused exploration\n            x, y = np.random.normal([best_x, best_y], search_width)\n            x, y = np.clip(x, *bounds), np.clip(y, *bounds)\n        else:\n            # Global search: explore new random point\n            x, y = np.random.uniform(*bounds, size=2)\n            \n        value = evaluate_function(x, y)\n        \n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n\n### Program D2 (Score: 0.9644)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm for function minimization.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random point (simplified)\n    best_x, best_y = np.random.uniform(bounds[0], bounds[1], size=2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search (simplified)\n        x, y = np.random.uniform(bounds[0], bounds[1], size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nKey features: Alternative approach to runs_successfully, Alternative approach to value_score\n\n## Inspiration Programs\n\nThese programs represent diverse approaches and creative solutions that may inspire new ideas:\n\n### Inspiration 1 (Score: 0.9881, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Hybrid random search algorithm for function minimization within specified bounds.\n    \n    Combines global exploration with local refinement around promising solutions to \n    balance exploration and exploitation of the search space.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random coordinates\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n    \n    # Probability of performing local search around best solution\n    local_search_prob = 0.2\n\n    for _ in range(iterations):\n        # Hybrid search strategy: balance exploration and exploitation\n        if np.random.random() < local_search_prob:\n            # Local search: refine around current best solution with fixed perturbation\n            x = np.clip(best_x + np.random.normal(0, 0.5), bounds[0], bounds[1])\n            y = np.clip(best_y + np.random.normal(0, 0.5), bounds[0], bounds[1])\n        else:\n            # Global search: explore new random point\n            x, y = np.random.uniform(*bounds, size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 27 lines with 37 lines, Excellent runs_successfully (1.000), Excellent value_score (0.997)\n\n\n### Inspiration 2 (Score: 0.0000, Type: Exploratory)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    Random search algorithm for function minimization within specified bounds.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random starting point\n    best_x, best_y = np.random.uniform(bounds[0], bounds[1], size=2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Generate new candidate point\n        x, y = np.random.uniform(bounds[0], bounds[1], size=2)\n        current_value = evaluate_function(x, y)\n\n        if current_value < best_value:\n            best_value = current_value\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Alternative runs_successfully approach, NumPy-based implementation, Comprehensive implementation\n\n\n### Inspiration 3 (Score: 0.9644, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm for function minimization.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random point (simplified)\n    best_x, best_y = np.random.uniform(bounds[0], bounds[1], size=2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search (simplified)\n        x, y = np.random.uniform(bounds[0], bounds[1], size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Excellent runs_successfully (1.000), Excellent value_score (0.976), Excellent overall_score (0.986)\n\n\n### Inspiration 4 (Score: 0.9566, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_point = np.random.uniform(bounds[0], bounds[1], size=2)\n    best_x, best_y = best_point\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Simple random search\n        point = np.random.uniform(bounds[0], bounds[1], size=2)\n        x, y = point\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 4 lines with 4 lines\nChange 2: Replace 4 lines with 4 lines, Excellent runs_successfully (1.000), Excellent value_score (0.970)\n\n\n### Inspiration 5 (Score: 0.9548, Type: High-Performer)\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm for function minimization.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    best_x, best_y = np.random.uniform(bounds[0], bounds[1], 2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        x, y = np.random.uniform(bounds[0], bounds[1], 2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\nUnique approach: Modification: Change 1: Replace 7 lines with 6 lines, Excellent runs_successfully (1.000), Excellent value_score (0.964)\n\n\n\n# Current Program\n```python\n# EVOLVE-BLOCK-START\n\"\"\"Function minimization example for OpenEvolve\"\"\"\nimport numpy as np\n\n\ndef search_algorithm(iterations=1000, bounds=(-5, 5)):\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    # Simplified bounds unpacking\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Generate candidate point\n        # Simplified bounds unpacking\n        x, y = np.random.uniform(*bounds, size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n    return best_x, best_y, best_value\n\n\n# EVOLVE-BLOCK-END\n\n\n# This part remains fixed (not evolved)\ndef evaluate_function(x, y):\n    \"\"\"The complex function we're trying to minimize\"\"\"\n    return np.sin(x) * np.cos(y) + np.sin(x * y) + (x**2 + y**2) / 20\n\n\ndef run_search():\n    x, y, value = search_algorithm()\n    return x, y, value\n\n\nif __name__ == \"__main__\":\n    x, y, value = run_search()\n    print(f\"Found minimum at ({x}, {y}) with value {value}\")\n\n```\n\n# Task\nSuggest improvements to the program that will lead to better performance on the specified metrics.\n\nYou MUST use the exact SEARCH/REPLACE diff format shown below to indicate changes:\n\n<<<<<<< SEARCH\n# Original code to find and replace (must match exactly)\n=======\n# New replacement code\n>>>>>>> REPLACE\n\nExample of valid diff format:\n<<<<<<< SEARCH\nfor i in range(m):\n    for j in range(p):\n        for k in range(n):\n            C[i, j] += A[i, k] * B[k, j]\n=======\n# Reorder loops for better memory access pattern\nfor i in range(m):\n    for k in range(n):\n        for j in range(p):\n            C[i, j] += A[i, k] * B[k, j]\n>>>>>>> REPLACE\n\nYou can suggest multiple changes. Each SEARCH section must exactly match code in the current program.\nBe thoughtful about your changes and explain your reasoning thoroughly.\n\nIMPORTANT: Do not rewrite the entire program - focus on targeted improvements.\n", "responses": ["# Performance Improvement Suggestions\n\nBased on the analysis, the current program has declined in several key metrics compared to previous versions. The primary issue appears to be the loss of the hybrid search strategy that balanced global exploration with local refinement.\n\n## 1. Restore Hybrid Search Strategy\n\nThe current program only performs global random search, which explains why it \"often gets stuck in local minima\" as mentioned in the docstring. Let's reintroduce the hybrid approach from the top-performing programs:\n\n<<<<<<< SEARCH\n    \"\"\"\n    A simple random search algorithm that often gets stuck in local minima.\n\n    Args:\n        iterations: Number of iterations to run\n        bounds: Bounds for the search space (min, max)\n\n    Returns:\n        Tuple of (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with a random point\n    # Simplified bounds unpacking\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n\n    for _ in range(iterations):\n        # Generate candidate point\n        # Simplified bounds unpacking\n        x, y = np.random.uniform(*bounds, size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n=======\n    \"\"\"\n    Hybrid random search algorithm for function minimization within specified bounds.\n    \n    Combines global exploration with local refinement around promising solutions to \n    balance exploration and exploitation of the search space.\n\n    Args:\n        iterations: Number of iterations to run (default: 1000)\n        bounds: Tuple specifying search space boundaries (min, max) (default: (-5, 5))\n\n    Returns:\n        Tuple containing (best_x, best_y, best_value)\n    \"\"\"\n    # Initialize with random coordinates\n    best_x, best_y = np.random.uniform(*bounds, size=2)\n    best_value = evaluate_function(best_x, best_y)\n    \n    # Probability of performing local search around best solution\n    local_search_prob = 0.2\n\n    for _ in range(iterations):\n        # Hybrid search strategy: balance exploration and exploitation\n        if np.random.random() < local_search_prob:\n            # Local search: refine around current best solution with fixed perturbation\n            x = np.clip(best_x + np.random.normal(0, 0.5), bounds[0], bounds[1])\n            y = np.clip(best_y + np.random.normal(0, 0.5), bounds[0], bounds[1])\n        else:\n            # Global search: explore new random point\n            x, y = np.random.uniform(*bounds, size=2)\n        value = evaluate_function(x, y)\n\n        if value < best_value:\n            best_value = value\n            best_x, best_y = x, y\n\n>>>>>>> REPLACE\n\n## Explanation of Changes\n\n1. **Restored Hybrid Search Strategy**: Reintroduced the 20% probability of local search around the current best solution, which was present in the top-performing programs but missing from the current version.\n\n2. **Local Refinement**: Added code to generate points around the current best solution using a normal distribution with small standard deviation (0.5), then clipping to ensure they stay within bounds.\n\n3. **Improved Documentation**: Updated the docstring to accurately reflect the hybrid nature of the algorithm and provide more detailed information, matching the style of the top-performing Program 1.\n\nThese changes should significantly improve:\n- **value_score**: By escaping local minima through systematic local refinement\n- **distance_score**: By finding better solutions closer to the true minimum\n- **standard_deviation_score**: By producing more consistent results across runs\n- **combined_score**: Through the cumulative effect of the above improvements\n\nThe hybrid approach maintains the 100% success rate and speed while dramatically improving the quality of solutions found."]}}}